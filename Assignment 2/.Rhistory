OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree=2000)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree=2000)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
(B = which(OOB.error == OOB.error[2000]))
(B = which(OOB.error == OOB.error[1000]))
suppressMessages(library(randomForest))
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree=1000)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree=1000)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
set.seed(500)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree=1000)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
set.seed(500)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree=1000)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
set.seed(500)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree=1000)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
set.seed(90138)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree=1000)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
set.seed(90138)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree=1000)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree=1000)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
(B = which(OOB.error == OOB.error[1000]))
suppressMessages(library(randomForest))
set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree=500)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
(B = which(OOB.error == OOB.error[1000]))
(B = which(OOB.error == OOB.error[500]))
(B = which(OOB.error == OOB.error[500]))
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
(B = which(OOB.error == OOB.error[500]))
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
which(OOB.error == OOB.error[500])
# Refit the random forest classifier using the chosen number of tree
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree = 211)
varImpPlot(rainfall.rf)
?varImpPlot
varImpPlot(rainfall.rf)
fig.dim = c(8, 6)
varImpPlot(rainfall.rf)
fig.dim = c(8, 8)
varImpPlot(rainfall.rf)
fig.dim = c(8, 10)
varImpPlot(rainfall.rf)
library(MASS)
library(pls)
XGtrain <- read.table(file = "XGtrainRain.txt", header = TRUE, sep = ",")
XGtest <- read.table(file = "XGtestRain.txt", header = TRUE, sep = ",")
library(randomForest)
m.rf <- randomForest(formula=factor(G) ~. , data=XGtrain, ntree=3000, importance = TRUE)
OOB.error <- m.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'blue', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'),lty=c(1,2),inset=.01)
(B=which(OOB.error==OOB.error[3000]))
B = 220
m.rf <- randomForest(formula=factor(G) ~. , data=XGtrain, ntree=B, importance = TRUE)
varImpPlot(m.rf)
m.rf$importance[order(m.rf$importance[,3], decreasing = TRUE)[1:30], 3:4]
m.rf$importance[order(m.rf$importance[,3], decreasing = TRUE)[1:30], 3:4]
rainfall.rf$importance[order(rainfall.rf$importance[,3], decreasing = TRUE)[1:30], 3:4]
test_prediction <- predict(rainfall.rf, XGtest[,1:365])
(rf.error <- sum(test_prediction != XGtest$G) / length(XGtest))
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
which(OOB.error == OOB.error[500])
# Refit the random forest classifier using the chosen number of tree
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree = 211)
fig.dim = c(8, 10)
varImpPlot(rainfall.rf)
rainfall.rf$importance[order(rainfall.rf$importance[,3], decreasing = TRUE)[1:30], 3:4]
test_prediction <- predict(rainfall.rf, XGtest[,1:365])
(rf.error <- sum(test_prediction != XGtest$G) / length(XGtest))
test_prediction <- predict(rainfall.rf, XGtest[,1:365])
(rf.error <- sum(test_prediction != XGtest$G) / length(XGtest))
test_prediction <- predict(rainfall.rf, XGtest[,1:365])
(rf.error <- sum(test_prediction != XGtest$G) / length(XGtest))
test_prediction <- predict(rainfall.rf, XGtest[,1:365])
rf.error <- sum(test_prediction != XGtest$G) / length(XGtest)
paste("Classification error", rf.error)
# Try refitting and running the tree 10 times
for (i in 1:10) {
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree = 211)
test_prediction <- predict(rainfall.rf, XGtest[,1:365])
rf.error <- sum(test_prediction != XGtest$G) / length(XGtest)
paste("Classification error", rf.error)
}
# Try refitting and running the tree 10 times
for (i in 1:10) {
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree = 211)
test_prediction <- predict(rainfall.rf, XGtest[,1:365])
rf.error <- sum(test_prediction != XGtest$G) / length(XGtest)
paste("Classification error", rf.error)
}
# Try refitting and running the tree 10 times
for (i in 1:10) {
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree = 211)
test_prediction <- predict(rainfall.rf, XGtest[,1:365])
rf.error <- sum(test_prediction != XGtest$G) / length(XGtest)
print(paste("Classification error", rf.error))
}
test_prediction <- predict(rainfall.rf, XGtest[,1:365])
rf.error <- sum(test_prediction != XGtest$G) / length(XGtest)
paste("Classification error:", rf.error)
test_prediction <- predict(rainfall.rf, XGtest[,1:365])
rf.error <- sum(test_prediction != XGtest$G) / length(XGtest)
paste("Classification error:", rf.error)
# Try refitting and running the tree 10 times
for (i in 1:10) {
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree = 211)
test_prediction <- predict(rainfall.rf, XGtest[,1:365])
rf.error <- sum(test_prediction != XGtest$G) / length(XGtest)
print(paste("Classification error:", rf.error))
}
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree = 1000)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree = 1000)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree = 1000)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree = 1000)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
# Try refitting and running the tree 10 times
for (i in 1:10) {
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree = 435)
test_prediction <- predict(rainfall.rf, XGtest[,1:365])
rf.error <- sum(test_prediction != XGtest$G) / length(XGtest)
print(paste("Classification error:", rf.error))
}
# Try refitting and running the tree 10 times
for (i in 1:10) {
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree = 435)
test_prediction <- predict(rainfall.rf, XGtest[,1:365])
rf.error <- sum(test_prediction != XGtest$G) / length(XGtest)
print(paste("Classification error:", rf.error))
}
rbind(LR_PCA_ERROR, LR_PLS_ERROR, QDA_PCA_ERROR, QDA_PLS_ERROR, rf.error)
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
suppressMessages(library(pls))
XGtrain <- read.table("XGtrainRain.txt", header = TRUE, sep = ",")
XGtest <- read.table("XGtestRain.txt", header = TRUE, sep = ",")
# Fitting the quadratic discriminant model
# qda_model <- qda(G~., data = XGtrain)
# Fitting the logistic regression model
logistic <- glm(G~., data = XGtrain, family = binomial(link = "logit"))
# summary(logistic)
# Obtain the projection matrix for PCA
Xtrain <- scale(XGtrain[, -c(366)], scale=FALSE)
PCX <- prcomp(Xtrain, retx = T)
gamma <- PCX$rotation
# Manually re-compute the PC components
Y <- (Xtrain - matrix(rep(1, nrow(Xtrain)), nrow=nrow(Xtrain)) %*% colMeans(Xtrain)) %*% gamma
all(PCX$x == Y)
# Obtain the projection matrix for PLS
PLS <- plsr(G~., data = XGtrain)
phi <- PLS$projection
t <- Xtrain %*% phi
all(PLS$scores == t)
# Train QDA with PLS components
CV_error <- rep(0, 50)
Gtrain <- XGtrain[, 366]
for (q in 1:50) {
prediction <- c()
for (i in 1:dim(XGtrain)[1]) {
GDATACV <- Gtrain[-i]
YDATACV <- as.data.frame(PLS$scores[-i, 1:q])
QDA <- qda(GDATACV~., data = YDATACV)
new_data <- as.data.frame(t(PLS$scores[i, 1:q]))
colnames(new_data) <- colnames(YDATACV)
prediction[i] <- as.numeric(predict(QDA, newdata = new_data)$class) - 1
}
CV_error[q] <- sum(prediction != Gtrain)/dim(XGtrain)[1]
}
# Plotting the cross validation error
plot(c(1:50), CV_error, type = "l", xlab = "Values of q", ylab = "CV Error", main = "PLS CV Error")
which(CV_error == min(CV_error))
min(CV_error)
# Train QDA with PCA components
CV_error <- rep(0, 50)
for (q in 1:50) {
prediction <- c()
for (i in 1:dim(XGtrain)[1]) {
GDATACV <- Gtrain[-i]
YDATACV <- as.data.frame(PCX$x[-i, 1:q])
QDA <- qda(GDATACV~., data = YDATACV)
new_data <- as.data.frame(t(PCX$x[i, 1:q]))
colnames(new_data) <- colnames(YDATACV)
prediction[i] <- as.numeric(predict(QDA, newdata = new_data)$class) - 1
}
CV_error[q] <- sum(prediction != Gtrain)/dim(XGtrain)[1]
}
# Plotting the cross validation error
plot(c(1:50), CV_error, type = "l", xlab = "Values of q", ylab = "CV Error", main = "PCA CV Error")
which(CV_error == min(CV_error))
min(CV_error)
# Train logistic regression model with PLS
CV_error <- rep(0, 50)
for (q in 1:50) {
prediction <- c()
for (i in 1:dim(XGtrain)[1]) {
GDATACV <- Gtrain[-i]
YDATACV <- as.data.frame(PLS$scores[-i, 1:q])
suppressWarnings(logistic <- glm(GDATACV~., data = YDATACV, family = binomial(link = "logit")))
new_data <- as.data.frame(t(PLS$scores[i, 1:q]))
colnames(new_data) <- colnames(YDATACV)
prediction[i] <- ifelse(predict(logistic, newdata = new_data) > 0, 1, 0)
}
CV_error[q] <- sum(prediction != Gtrain)/dim(XGtrain)[1]
}
# Plotting the cross validation error
plot(c(1:50), CV_error, type = "l", xlab = "Values of q", ylab = "CV Error", main = "PLS CV Error")
which(CV_error == min(CV_error))
min(CV_error)
# Train logistic regression model with PCA components
CV_error <- rep(0, 50)
for (q in 1:50) {
prediction <- c()
for (i in 1:dim(XGtrain)[1]) {
GDATACV <- Gtrain[-i]
YDATACV <- as.data.frame(PCX$x[-i, 1:q])
suppressWarnings(logistic <- glm(GDATACV~., data = YDATACV, family = binomial(link = "logit")))
new_data <- as.data.frame(t(PCX$x[i, 1:q]))
colnames(new_data) <- colnames(YDATACV)
prediction[i] <- ifelse(predict(logistic, newdata = new_data) > 0, 1, 0)
}
CV_error[q] <- sum(prediction != Gtrain)/dim(XGtrain)[1]
}
# Plotting the cross validation error
plot(c(1:50), CV_error, type = "l", xlab = "Values of q", ylab = "CV Error", main = "PLS CV Error")
which(CV_error == min(CV_error))
min(CV_error)
# Retrain all the classifiers with the suggested value of q and the full training set
QDA_PLS <- qda(Gtrain~., data = as.data.frame(PLS$scores[, 1:15]))
QDA_PCA <- qda(Gtrain~., data = as.data.frame(PCX$x[, 1:6]))
logistic_PLS <- glm(Gtrain~., data = as.data.frame(PLS$scores[, 1:14]), family = binomial(link = "logit"))
logistic_PCA <- glm(Gtrain~., data = as.data.frame(PCX$x[, 1:4]), family = binomial(link = "logit"))
# Prepare the test set
Xtest <- XGtest[,-c(366)]
Gtest <- XGtest[, 366]
repbarX <- matrix(rep(colMeans(XGtrain), dim(Xtest)[1]), nrow = dim(Xtest)[1], byrow = T)
Y_new <- as.matrix(Xtest - repbarX) %*% gamma
# Report test error for quadratic discriminant with PCA components
PCA_newdata <- as.data.frame(Y_new[, 1:6])
prediction <- predict(QDA_PCA, newdata = PCA_newdata)$class
QDA_PCA_ERROR <- sum(prediction != Gtest)/dim(Xtest)[1]
paste("Test error for quadratic discriminant with PCA components is", QDA_PCA_ERROR)
# Report test error for logistic regression with PCA components
PCA_newdata <- as.data.frame(Y_new[, 1:4])
prediction <- ifelse(predict(logistic_PCA, newdata = PCA_newdata) > 0, 1, 0)
LR_PCA_ERROR <- sum(prediction != Gtest)/dim(Xtest)[1]
paste("Test error for logistic regression with PCA components is", LR_PCA_ERROR)
# Report test error for quadratic discriminant with PLS components
t_new <- as.matrix(Xtest - repbarX) %*% phi
PLS_newdata <- as.data.frame(t_new[, 1:15])
prediction <- predict(QDA_PLS, newdata = PLS_newdata)$class
QDA_PLS_ERROR <- sum(prediction != Gtest)/dim(Xtest)[1]
paste("Test error for quadratic discriminant with PLS components is", QDA_PLS_ERROR)
# Report test error for logistic regression with PLS components
PLS_newdata <- as.data.frame(t_new[, 1:14])
prediction <- ifelse(predict(logistic_PLS, newdata = PLS_newdata) > 0, 1, 0)
LR_PLS_ERROR <- sum(prediction != Gtest)/dim(Xtest)[1]
paste("Test error for logistic regression with PLS components is", LR_PLS_ERROR)
suppressMessages(library(randomForest))
# set.seed(90139)
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree = 1000)
OOB.error <- rainfall.rf$err.rate[,1]
plot(OOB.error, type = "l")
abline(h = mean(OOB.error), col = 'red', xlab = "number of trees used", lty = 2)
title("OOB error against the number of trees used")
legend("topright", c('OOB.Error','Mean'), col=c('black','4'), lty=c(1,2), inset=.01)
which(OOB.error == OOB.error[500])
# Refit the random forest classifier using the chosen number of tree
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree = 211)
fig.dim = c(8, 10)
varImpPlot(rainfall.rf)
rainfall.rf$importance[order(rainfall.rf$importance[,3], decreasing = TRUE)[1:30], 3:4]
test_prediction <- predict(rainfall.rf, XGtest[,1:365])
RF_ERROR <- sum(test_prediction != XGtest$G) / length(XGtest)
paste("Classification error:", RF_ERROR)
# Try refitting and running the tree 10 times
for (i in 1:10) {
rainfall.rf <- randomForest(factor(G)~., data = XGtrain, importance = TRUE, ntree = 435)
test_prediction <- predict(rainfall.rf, XGtest[,1:365])
RF_ERROR <- sum(test_prediction != XGtest$G) / length(XGtest)
print(paste("Classification error:", RF_ERROR))
}
classifier.name <- c('Logistic + PCA', 'Logistic + PLS', 'QDA + PCA', 'QDA + PLS', 'RF')
rbind(LR_PCA_ERROR, LR_PLS_ERROR, QDA_PCA_ERROR, QDA_PLS_ERROR, RF_ERROR)
